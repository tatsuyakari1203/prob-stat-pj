\section{Data Description}
\label{sec:data_description}

\subsection{Raw Dataset Overview}
The dataset for this project is the "Internet Advertisements Data Set" from the UCI Machine Learning Repository. It contains 3,279 instances, where the task is to classify each image as an advertisement ("ad") or not ("nonad").

Based on the official documentation, the 1,559 features provided for classification can be summarized into three main categories:
\begin{itemize}
    \item \textbf{Geometric Properties:} Three continuous features representing the image's height, width, and aspect ratio.
    \item \textbf{Phrase-based Features:} Over 1,500 binary features indicating the presence of specific advertising-related words or phrases in the image's URL, alt text, and surrounding text.
    \item \textbf{URL-based Features:} A smaller set of binary features derived from keywords within the page and image URLs.
\end{itemize}

The target variable, indicating the class, is located in the final column of the dataset.

\textbf{Initial Dataset Characteristics:}
\begin{itemize}
    \item Total samples: 3,279 internet images
    \item Original features: 1,560 columns (including index and target)
    \item Feature columns: X0 to X1557 (1,558 numerical attributes)
    \item Target column: X1558 with values 'ad.' and 'nonad.'
    \item File format: CSV with headers
\end{itemize}

\subsection{Raw Data Loading Process}
The dataset is loaded from a CSV file using the following R code:

\begin{lstlisting}[language=R]
# Load the dataset from the CSV file
data <- read.csv("../add.csv", header = TRUE, stringsAsFactors = FALSE)

# Identify the target column name
target_col <- names(data)[ncol(data)]
\end{lstlisting}

\subsection{Raw Data Target Distribution}
The target variable shows a significant class imbalance:
\begin{itemize}
    \item Advertisement images (ad): 459 observations (14\%)
    \item Non-advertisement images (nonad): 2,820 observations (86\%)
\end{itemize}

This imbalance is typical in advertisement detection problems and will need to be considered when building and evaluating classification models.

\subsection{Missing Values in Raw Data}
The dataset contains missing values represented as "?" strings. Initial analysis revealed:
\begin{itemize}
    \item Total missing values: 15 occurrences across the entire dataset
    \item All missing values are concentrated in column 5 (X4)
    \item Missing values represent approximately 0.46\% of column 5's data (15 out of 3,279 observations)
    \item No other columns contain missing values
    \item Missing values are handled during preprocessing by converting "?" to NA, then imputing with median values
\end{itemize}

\textbf{Missing Value Detection Process:}
\begin{lstlisting}[language=R]
# Check for missing values represented as "?"
missing_count <- sum(data == "?", na.rm = TRUE)
cat("Total '?' values in dataset:", missing_count)

# Check missing values by column
for(i in 1:min(20, ncol(data))) {
  missing_in_col <- sum(data[[i]] == "?", na.rm = TRUE)
  if(missing_in_col > 0) {
    cat("Column", i, ":", missing_in_col, "missing values")
  }
}
\end{lstlisting}

\subsection{Data Cleaning and Preprocessing Pipeline}
Several preprocessing steps were applied to prepare the data for analysis:

\begin{lstlisting}[language=R]
# 1. Remove the first column which is an unnecessary index
data <- data[, -1]

# 2. Handle missing values represented by "?"
# Convert "?" to NA for all feature columns
for(i in 1:(ncol(data)-1)) {
  data[[i]] <- as.numeric(ifelse(data[[i]] == "?", NA, data[[i]]))
}

# 3. Impute missing values using the median of each column
for(i in 1:(ncol(data)-1)) {
  if(any(is.na(data[[i]]))) {
    median_val <- median(data[[i]], na.rm = TRUE)
    data[[i]][is.na(data[[i]])] <- median_val
  }
}

# 4. Clean and format the target variable
data[[target_col]] <- factor(data[[target_col]], 
                            levels = c("ad.", "nonad."), 
                            labels = c("ad", "nonad"))
\end{lstlisting}

The preprocessing pipeline includes:
\begin{enumerate}
    \item \textbf{Index removal}: The first column containing row indices was removed
    \item \textbf{Missing value handling}: All "?" strings were converted to NA values
    \item \textbf{Median imputation}: Missing values were replaced with the median of their respective columns
    \item \textbf{Target variable formatting}: The target variable was converted to a factor with clear labels ("ad" and "nonad")
\end{enumerate}

\subsection{Clean Data Characteristics}
After preprocessing, the cleaned dataset has the following properties:
\begin{itemize}
    \item Dimensions: 3,279 rows × 1,559 columns
    \item All missing values have been imputed
    \item Target variable is properly formatted as a factor
    \item All feature columns are numeric
    \item Class distribution remains: 459 advertisements, 2,820 non-advertisements
\end{itemize}

\subsection{Clean Data Statistical Summary}
Preliminary statistics for the first five feature columns (after preprocessing) show:

\begin{table}[h]
\centering
\caption{Descriptive Statistics for First Five Feature Columns}
\label{tab:basic_stats}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Column} & \textbf{Mean} & \textbf{Median} & \textbf{SD} & \textbf{Notes} \\
\hline
Column 1 (X0) & 1,639.00 & 1,639.00 & 946.71 & No missing values \\
Column 2 (X1) & 64.02 & 51.00 & 54.87 & No missing values \\
Column 3 (X2) & 155.34 & 110.00 & 130.03 & No missing values \\
Column 4 (X3) & 3.91 & 2.10 & 6.04 & No missing values \\
Column 5 (X4) & 0.77 & 1.00 & 0.42 & Had 15 missing values (imputed) \\
\hline
\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
    \item Features exhibit varying scales (from 0.77 to 1,639 in mean values)
    \item Standard deviations range from 0.42 to 946.71, indicating high variability in feature scales
    \item Column 5 (X4) was the only column requiring missing value imputation
    \item Normalization or standardization will be beneficial for distance-based algorithms
\end{itemize}

\subsection{Data Cleaning Process Summary}
The complete data cleaning process involved four main steps as documented in the preprocessing pipeline:

\begin{enumerate}
    \item \textbf{Remove Index Column}: Removed the first column (X) which was a row index
    \item \textbf{Handle Missing Values}: Converted '?' strings to NA values for proper handling
    \item \textbf{Impute with Median}: Replaced all NA values in numeric columns with the column median
    \item \textbf{Clean Target Variable}: Converted the target variable to a factor with levels 'ad' and 'nonad'
\end{enumerate}

\textbf{Cleaning Results:}
\begin{itemize}
    \item Final dimensions: 3,279 rows × 1,559 columns
    \item Missing values after cleaning: 0
    \item Target distribution preserved: 459 advertisements, 2,820 non-advertisements
    \item All feature columns converted to numeric format
    \item Target variable properly formatted as factor
\end{itemize}